# -*- coding: utf-8 -*-
"""XN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18plR6654ibD4sqtKobQj5bXtzNABjP8_
"""

!pip install streamlit

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import base64

# 1. Import Libraries
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from sklearn.inspection import permutation_importance
from sklearn.metrics import mean_squared_error, mean_absolute_error

# 2. Load and Clean Bridge Log Data
bridge_df = pd.read_excel("/content/Chelsea Bridge Data Points_03272025.xlsx", sheet_name="Data", header=3)
bridge_df = bridge_df[["ETA Bridge", "Start Time", "End Time", "Duration", "Vessel(s)", "Direction"]].dropna()
bridge_df["ETA Bridge"] = pd.to_datetime(bridge_df["ETA Bridge"])
bridge_df["Start Time"] = pd.to_datetime(bridge_df["Start Time"])
bridge_df["End Time"] = pd.to_datetime(bridge_df["End Time"])

# Convert Duration to Minutes
def time_to_minutes(t):
    return t.hour * 60 + t.minute + t.second / 60 if pd.notnull(t) else None
bridge_df["Lift_Duration_Minutes"] = bridge_df["Duration"].apply(time_to_minutes)
bridge_df.drop(columns=["Duration"], inplace=True)
bridge_df.dropna(subset=["Lift_Duration_Minutes"], inplace=True)

# 3. Feature Engineering
bridge_df["Day_of_Week"] = bridge_df["ETA Bridge"].dt.dayofweek
bridge_df["time_of_day"] = pd.cut(bridge_df["ETA Bridge"].dt.hour, bins=[0, 6, 12, 18, 24], labels=[1, 2, 3, 4], right=False).astype(int)
bridge_df["Start_Minutes"] = bridge_df["Start Time"].dt.hour * 60 + bridge_df["Start Time"].dt.minute
bridge_df["End_Minutes"] = bridge_df["End Time"].dt.hour * 60 + bridge_df["End Time"].dt.minute
bridge_df["Vessel_Count"] = bridge_df["Vessel(s)"].astype(str).apply(lambda x: len(x.split(",")))
bridge_df["Has_Barge"] = bridge_df["Vessel(s)"].str.contains("Barge", case=False, na=False).astype(int)
bridge_df["Has_Tanker"] = bridge_df["Vessel(s)"].str.contains("Tanker", case=False, na=False).astype(int)

# 4. Fetch NOAA Tide Data
tide_url = (
    "https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?"
    "product=predictions&application=bridge_lift_model"
    "&begin_date=20240501&end_date=20240601&datum=MLLW"
    "&station=8443970&time_zone=gmt&units=english&interval=h&format=json"
)
response = requests.get(tide_url)
tide_json = response.json()
df_tide = pd.DataFrame(tide_json.get("predictions", []))
df_tide["datetime"] = pd.to_datetime(df_tide["t"])
df_tide["tide_ft"] = df_tide["v"].astype(float)
df_tide["datetime_hour"] = df_tide["datetime"].dt.floor("h")

# 5. Fetch Open-Meteo Weather Data
latitude = 42.3917
longitude = -71.0336
start_date = "2024-05-01"
end_date = "2024-06-01"
url = (
    f"https://archive-api.open-meteo.com/v1/era5?"
    f"latitude={latitude}&longitude={longitude}"
    f"&start_date={start_date}&end_date={end_date}"
    f"&hourly=temperature_2m,precipitation,windspeed_10m"
)
response = requests.get(url)
data = response.json()
weather_df = pd.DataFrame({
    'datetime_hour': pd.to_datetime(data['hourly']['time']),
    'temperature_C': data['hourly']['temperature_2m'],
    'precipitation_mm': data['hourly']['precipitation'],
    'windspeed_mph': data['hourly']['windspeed_10m']
})
weather_df["Did_Rain"] = (weather_df["precipitation_mm"] > 0).astype(int)
weather_df["TAVG"] = weather_df["temperature_C"]

# 6. Merge All Sources
df = bridge_df.copy()
df["datetime_hour"] = df["ETA Bridge"].dt.floor("h")
df = df.merge(weather_df, on="datetime_hour", how="left")
df = df.merge(df_tide[["datetime_hour", "tide_ft"]], on="datetime_hour", how="left")
df["Is_Daylight"] = df["ETA Bridge"].dt.hour.between(6, 20).astype(int)
df["Hour"] = df["ETA Bridge"].dt.hour

# Fill missing values
df["temperature_C"] = df["temperature_C"].fillna(pd.Series(np.random.normal(18, 5, size=len(df))))
df["TAVG"] = df["TAVG"].fillna(df["temperature_C"])
df["precipitation_mm"] = df["precipitation_mm"].fillna(0)
df["Did_Rain"] = df["Did_Rain"].fillna(0)
df["windspeed_mph"] = df["windspeed_mph"].fillna(pd.Series(np.random.normal(10, 3, size=len(df))))
df["tide_ft"] = df["tide_ft"].fillna(pd.Series(np.random.uniform(0, 10, size=len(df))))

#  Exploratory Data Analysis (EDA)

# EDA 1: Distribution of Lift Durations
plt.figure(figsize=(10, 5))
sns.histplot(df['Lift_Duration_Minutes'], bins=30, kde=True, color='skyblue')
plt.title("Distribution of Bridge Lift Durations")
plt.xlabel("Lift Duration (Minutes)")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# EDA 2: Average Duration by Vessel Count
plt.figure(figsize=(10, 5))
sns.boxplot(x="Has_Tanker", y="Lift_Duration_Minutes", data=df)
plt.title("Lift Duration by Tanker Involvement")
plt.xlabel("Has Tanker (0 = No, 1 = Yes)")
plt.ylabel("Lift Duration (Minutes)")
plt.tight_layout()
plt.show()

# 7. Feature Selection
features = [
    "temperature_C", "precipitation_mm", "windspeed_mph", "tide_ft", "Is_Daylight",
    "Hour", "Day_of_Week", "time_of_day", "TAVG", "Did_Rain",
    "Vessel_Count", "Start_Minutes", "End_Minutes", "Has_Barge", "Has_Tanker"
]
X = df[features].dropna()
y = df.loc[X.index, "Lift_Duration_Minutes"]

# 8. Train/Test Split
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 9. MLP Regressor
mlp = MLPRegressor(hidden_layer_sizes=(16, 8), activation='relu', solver='adam', max_iter=500, random_state=42)
mlp.fit(X_train, y_train)

# 10. Feature Importance Plot
results = permutation_importance(mlp, X_test, y_test, n_repeats=30, random_state=42)
importance_df = pd.DataFrame({
    "Feature": features,
    "Importance": results.importances_mean
}).sort_values(by="Importance", ascending=False)

# 11. Evaluation Plot (Actual vs Predicted)
y_pred = mlp.predict(X_test)
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Duration (min)")
plt.ylabel("Predicted Duration (min)")
plt.title("MLP: Actual vs Predicted Duration")
plt.grid(True)
plt.tight_layout()
plt.show()

# Print Performance
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
within_5min = np.mean(np.abs(y_test - y_pred) <= 5) * 100
print(f"\nMLP Regressor Performance:\nRMSE: {rmse:.2f} min | MAE: {mae:.2f} min | Â±5min Accuracy: {within_5min:.2f}%")